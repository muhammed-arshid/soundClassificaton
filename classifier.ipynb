{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/arshid/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/arshid/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/arshid/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/arshid/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/arshid/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/arshid/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/arshid/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/arshid/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/arshid/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/arshid/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/arshid/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/arshid/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten,LSTM,TimeDistributed\n",
    "from keras.layers import Convolution2D, MaxPooling2D,MaxPooling1D,Conv1D\n",
    "from keras.optimizers import Adam,SGD\n",
    "from keras.utils import np_utils\n",
    "from sklearn import metrics\n",
    "import random\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import optimizers\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reSample(data, samples):\n",
    "    r = len(data)/samples #re-sampling ratio\n",
    "    newdata = []\n",
    "    for i in range(0,samples):\n",
    "        newdata.append(data[int(i*r)])\n",
    "    return np.array(newdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subjects = ['s07', 's16', 's09', 's13', 's04', 's11', 's15', 's01', 's12', 's10', 's06', 's08']\n",
    "validation_subjects = ['s02', 's03']\n",
    "test_subjects = ['s05', 's17']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(path,sampleSize):\n",
    "    \n",
    "    mergedActivities = ['Drinking', 'Eating', 'LyingDown', 'OpeningPillContainer', \n",
    "                          'PickingObject', 'Reading', 'SitStill', 'Sitting', 'Sleeping', \n",
    "                          'StandUp', 'UseLaptop', 'UsingPhone', 'WakeUp', 'Walking', \n",
    "                          'WaterPouring', 'Writing']\n",
    "    \n",
    "    specificActivities = ['Calling', 'Clapping', 'Falling', 'Sweeping', 'WashingHand', 'WatchingTV']\n",
    "    \n",
    "    enteringExiting = ['Entering', 'Exiting']\n",
    "    \n",
    "    X_train = []\n",
    "    Y_train = []\n",
    "    X_test = []\n",
    "    Y_test = []\n",
    "    X_validation = []\n",
    "    Y_validation = []\n",
    "    \n",
    "    ## Note that 'stft_257_1' contains the STFT features with specification specified in the medium article; \n",
    "    ## https://medium.com/@chathuranga.15/sound-event-classification-using-machine-learning-8768092beafc\n",
    "    \n",
    "    for file in os.listdir(path + 'STFT_file/'):\n",
    "        if int(file.split(\"__\")[1].split(\"_\")[0])!=1:\n",
    "          a = (np.load(path + \"STFT_file/\" + file)).T\n",
    "          label = file.split('_')[-1].split(\".\")[0]\n",
    "          if(label in specificActivities):\n",
    "              #if(a.shape[0]>100 and a.shape[0]<500):\n",
    "                if file.split(\"_\")[0] in train_subjects:\n",
    "#                   X_train.append(reSample(a,sampleSize))\n",
    "                  X_train.append(np.mean(a,axis=0))\n",
    "                  Y_train.append(label)\n",
    "                elif file.split(\"_\")[0] in validation_subjects:\n",
    "                  X_validation.append(np.mean(a,axis=0))\n",
    "                  Y_validation.append(label)\n",
    "                else:\n",
    "                  X_test.append(np.mean(a,axis=0))\n",
    "                  Y_test.append(label)\n",
    "                  #samples[label].append(reSample(a,sampleSize))\n",
    "          elif(label in enteringExiting):\n",
    "                label = \"enteringExiting\"\n",
    "              #if(a.shape[0]>100 and a.shape[0]<500):\n",
    "                if file.split(\"_\")[0] in train_subjects:\n",
    "                  X_train.append(np.mean(a,axis=0))\n",
    "                  Y_train.append(label)\n",
    "                elif file.split(\"_\")[0] in validation_subjects:\n",
    "                  X_validation.append(np.mean(a,axis=0))\n",
    "                  Y_validation.append(label)\n",
    "                else:\n",
    "                  X_test.append(np.mean(a,axis=0))\n",
    "                  Y_test.append(label)\n",
    "                  #samples[label].append(reSample(a,sampleSize))\n",
    "          else:\n",
    "                label = \"other\"\n",
    "              #if(a.shape[0]>100 and a.shape[0]<500):\n",
    "                if file.split(\"_\")[0] in train_subjects:\n",
    "                  X_train.append(np.mean(a,axis=0))\n",
    "                  Y_train.append(label)\n",
    "                elif file.split(\"_\")[0] in validation_subjects:\n",
    "                  X_validation.append(np.mean(a,axis=0))\n",
    "                  Y_validation.append(label)\n",
    "                else:\n",
    "                  X_test.append(np.mean(a,axis=0))\n",
    "                  Y_test.append(label)\n",
    "                  \n",
    "    X_train = np.array(X_train)\n",
    "    Y_train = np.array(Y_train)\n",
    "    X_test = np.array(X_test)\n",
    "    Y_test = np.array(Y_test)\n",
    "    X_validation = np.array(X_validation)\n",
    "    Y_validation = np.array(Y_validation)\n",
    "    \n",
    "    return X_train,Y_train,X_validation,Y_validation,X_test,Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_M(conf_M):\n",
    "        s = \"activity,\"\n",
    "        for i in range(len(conf_M)):\n",
    "            s += lb.inverse_transform([i])[0] + \",\"\n",
    "        print(s[:-1])\n",
    "        for i in range(len(conf_M)):\n",
    "            s = \"\"\n",
    "            for j in range(len(conf_M)):\n",
    "                s += str(conf_M[i][j])\n",
    "                s += \",\"\n",
    "            print(lb.inverse_transform([i])[0],\",\", s[:-1])\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_M_P(conf_M):\n",
    "        s = \"activity,\"\n",
    "        for i in range(len(conf_M)):\n",
    "            s += lb.inverse_transform([i])[0] + \",\"\n",
    "        print(s[:-1])\n",
    "        for i in range(len(conf_M)):\n",
    "            s = \"\"\n",
    "            for j in range(len(conf_M)):\n",
    "                val = conf_M[i][j]/float(sum(conf_M[i]))\n",
    "                s += str(round(val,2))\n",
    "                s += \",\"\n",
    "            print(lb.inverse_transform([i])[0],\",\", s[:-1])\n",
    "        print() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showResult():\n",
    "  predictions = [np.argmax(y) for y in result]\n",
    "  expected = [np.argmax(y) for y in y_test]\n",
    "\n",
    "  conf_M = []\n",
    "  num_labels=y_test[0].shape[0]\n",
    "  for i in range(num_labels):\n",
    "      r = []\n",
    "      for j in range(num_labels):\n",
    "          r.append(0)\n",
    "      conf_M.append(r)\n",
    "    \n",
    "    \n",
    "  n_tests = len(predictions)\n",
    "  for i in range(n_tests):        \n",
    "      conf_M[expected[i]][predictions[i]] += 1\n",
    "\n",
    "  print_M(conf_M)\n",
    "  print_M_P(conf_M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresPath = \"stft/\"\n",
    "\n",
    "a,b,c,d,e,f = get_data(featuresPath,250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of training samples: 880\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train,Y_train,X_validation,Y_validation,X_test,Y_test = a,b,c,d,e,f\n",
    "\n",
    "n_samples = len(Y_train)\n",
    "print(\"No of training samples: \" + str(n_samples))\n",
    "order = np.array(range(n_samples))\n",
    "np.random.shuffle(order)\n",
    "X_train = X_train[order]\n",
    "Y_train = Y_train[order]\n",
    "\n",
    "lb = LabelEncoder()\n",
    "y_train = np_utils.to_categorical(lb.fit_transform(Y_train))\n",
    "y_test = np_utils.to_categorical(lb.fit_transform(Y_test))\n",
    "y_validation = np_utils.to_categorical(lb.fit_transform(Y_validation))\n",
    "num_labels = y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 880 samples, validate on 146 samples\n",
      "Epoch 1/60\n",
      "880/880 [==============================] - 1s 1ms/step - loss: 1.3489 - accuracy: 0.7341 - val_loss: 0.6723 - val_accuracy: 0.8082\n",
      "Epoch 2/60\n",
      "880/880 [==============================] - 0s 489us/step - loss: 0.7977 - accuracy: 0.7705 - val_loss: 0.6154 - val_accuracy: 0.8014\n",
      "Epoch 3/60\n",
      "880/880 [==============================] - 0s 510us/step - loss: 0.7743 - accuracy: 0.7773 - val_loss: 0.5962 - val_accuracy: 0.8082\n",
      "Epoch 4/60\n",
      "880/880 [==============================] - 0s 496us/step - loss: 0.7346 - accuracy: 0.7784 - val_loss: 0.6006 - val_accuracy: 0.8151\n",
      "Epoch 5/60\n",
      "880/880 [==============================] - 0s 498us/step - loss: 0.7092 - accuracy: 0.7943 - val_loss: 0.5222 - val_accuracy: 0.8219\n",
      "Epoch 6/60\n",
      "880/880 [==============================] - 0s 497us/step - loss: 0.6980 - accuracy: 0.7875 - val_loss: 0.4877 - val_accuracy: 0.8356\n",
      "Epoch 7/60\n",
      "880/880 [==============================] - 0s 503us/step - loss: 0.6326 - accuracy: 0.8125 - val_loss: 0.4785 - val_accuracy: 0.8356\n",
      "Epoch 8/60\n",
      "880/880 [==============================] - 0s 506us/step - loss: 0.7010 - accuracy: 0.7955 - val_loss: 0.4647 - val_accuracy: 0.8219\n",
      "Epoch 9/60\n",
      "880/880 [==============================] - 0s 523us/step - loss: 0.6513 - accuracy: 0.8045 - val_loss: 0.4167 - val_accuracy: 0.8699\n",
      "Epoch 10/60\n",
      "880/880 [==============================] - 0s 518us/step - loss: 0.5932 - accuracy: 0.8261 - val_loss: 0.3777 - val_accuracy: 0.8630\n",
      "Epoch 11/60\n",
      "880/880 [==============================] - 0s 517us/step - loss: 0.6081 - accuracy: 0.8057 - val_loss: 0.4303 - val_accuracy: 0.8562\n",
      "Epoch 12/60\n",
      "880/880 [==============================] - 0s 529us/step - loss: 0.5928 - accuracy: 0.8284 - val_loss: 0.4305 - val_accuracy: 0.8493\n",
      "Epoch 13/60\n",
      "880/880 [==============================] - 0s 513us/step - loss: 0.5882 - accuracy: 0.8148 - val_loss: 0.4155 - val_accuracy: 0.8562\n",
      "Epoch 14/60\n",
      "880/880 [==============================] - 0s 517us/step - loss: 0.5491 - accuracy: 0.8386 - val_loss: 0.3509 - val_accuracy: 0.8699\n",
      "Epoch 15/60\n",
      "880/880 [==============================] - 0s 527us/step - loss: 0.5191 - accuracy: 0.8500 - val_loss: 0.3535 - val_accuracy: 0.8836\n",
      "Epoch 16/60\n",
      "880/880 [==============================] - 1s 607us/step - loss: 0.5047 - accuracy: 0.8398 - val_loss: 0.3186 - val_accuracy: 0.9041\n",
      "Epoch 17/60\n",
      "880/880 [==============================] - 1s 582us/step - loss: 0.5121 - accuracy: 0.8500 - val_loss: 0.3495 - val_accuracy: 0.8836\n",
      "Epoch 18/60\n",
      "880/880 [==============================] - 1s 576us/step - loss: 0.5017 - accuracy: 0.8545 - val_loss: 0.3263 - val_accuracy: 0.9041\n",
      "Epoch 19/60\n",
      "880/880 [==============================] - 0s 523us/step - loss: 0.5063 - accuracy: 0.8466 - val_loss: 0.3090 - val_accuracy: 0.8973\n",
      "Epoch 20/60\n",
      "880/880 [==============================] - 1s 820us/step - loss: 0.4659 - accuracy: 0.8580 - val_loss: 0.3307 - val_accuracy: 0.8630\n",
      "Epoch 21/60\n",
      "880/880 [==============================] - 0s 538us/step - loss: 0.4571 - accuracy: 0.8591 - val_loss: 0.3499 - val_accuracy: 0.8630\n",
      "Epoch 22/60\n",
      "880/880 [==============================] - 0s 521us/step - loss: 0.4493 - accuracy: 0.8545 - val_loss: 0.3051 - val_accuracy: 0.8836\n",
      "Epoch 23/60\n",
      "880/880 [==============================] - 0s 477us/step - loss: 0.4206 - accuracy: 0.8625 - val_loss: 0.3365 - val_accuracy: 0.8767\n",
      "Epoch 24/60\n",
      "880/880 [==============================] - 0s 481us/step - loss: 0.4239 - accuracy: 0.8727 - val_loss: 0.3175 - val_accuracy: 0.8630\n",
      "Epoch 25/60\n",
      "880/880 [==============================] - 0s 489us/step - loss: 0.4319 - accuracy: 0.8807 - val_loss: 0.2656 - val_accuracy: 0.9110\n",
      "Epoch 26/60\n",
      "880/880 [==============================] - 0s 480us/step - loss: 0.4047 - accuracy: 0.8693 - val_loss: 0.2917 - val_accuracy: 0.9041\n",
      "Epoch 27/60\n",
      "880/880 [==============================] - 0s 488us/step - loss: 0.4643 - accuracy: 0.8727 - val_loss: 0.3472 - val_accuracy: 0.8767\n",
      "Epoch 28/60\n",
      "880/880 [==============================] - 0s 496us/step - loss: 0.4229 - accuracy: 0.8705 - val_loss: 0.3364 - val_accuracy: 0.8836\n",
      "Epoch 29/60\n",
      "880/880 [==============================] - 0s 526us/step - loss: 0.3871 - accuracy: 0.8852 - val_loss: 0.2875 - val_accuracy: 0.9041\n",
      "Epoch 30/60\n",
      "880/880 [==============================] - 0s 566us/step - loss: 0.3882 - accuracy: 0.8818 - val_loss: 0.2867 - val_accuracy: 0.9041\n",
      "Epoch 31/60\n",
      "880/880 [==============================] - 0s 490us/step - loss: 0.3583 - accuracy: 0.8864 - val_loss: 0.3148 - val_accuracy: 0.8904\n",
      "Epoch 32/60\n",
      "880/880 [==============================] - 1s 572us/step - loss: 0.3705 - accuracy: 0.8898 - val_loss: 0.2983 - val_accuracy: 0.8904\n",
      "Epoch 33/60\n",
      "880/880 [==============================] - 1s 600us/step - loss: 0.3925 - accuracy: 0.8784 - val_loss: 0.3264 - val_accuracy: 0.8699\n",
      "Epoch 34/60\n",
      "880/880 [==============================] - 0s 522us/step - loss: 0.3562 - accuracy: 0.8920 - val_loss: 0.3684 - val_accuracy: 0.8836\n",
      "Epoch 35/60\n",
      "880/880 [==============================] - 0s 539us/step - loss: 0.4597 - accuracy: 0.8705 - val_loss: 0.4051 - val_accuracy: 0.8767\n",
      "Epoch 36/60\n",
      "880/880 [==============================] - 0s 543us/step - loss: 0.3538 - accuracy: 0.8875 - val_loss: 0.3405 - val_accuracy: 0.8767\n",
      "Epoch 37/60\n",
      "880/880 [==============================] - 0s 494us/step - loss: 0.3445 - accuracy: 0.9023 - val_loss: 0.3090 - val_accuracy: 0.8904\n",
      "Epoch 38/60\n",
      "880/880 [==============================] - 0s 479us/step - loss: 0.3020 - accuracy: 0.9057 - val_loss: 0.3058 - val_accuracy: 0.9178\n",
      "Epoch 39/60\n",
      "880/880 [==============================] - 0s 490us/step - loss: 0.2871 - accuracy: 0.9182 - val_loss: 0.3537 - val_accuracy: 0.8904\n",
      "Epoch 40/60\n",
      "880/880 [==============================] - 1s 576us/step - loss: 0.2896 - accuracy: 0.9159 - val_loss: 0.3446 - val_accuracy: 0.8973\n",
      "Epoch 41/60\n",
      "880/880 [==============================] - 0s 501us/step - loss: 0.2986 - accuracy: 0.9125 - val_loss: 0.3310 - val_accuracy: 0.8836\n",
      "Epoch 42/60\n",
      "880/880 [==============================] - 0s 480us/step - loss: 0.2841 - accuracy: 0.9261 - val_loss: 0.3857 - val_accuracy: 0.8904\n",
      "Epoch 43/60\n",
      "880/880 [==============================] - 0s 491us/step - loss: 0.3051 - accuracy: 0.9057 - val_loss: 0.3722 - val_accuracy: 0.8973\n",
      "Epoch 44/60\n",
      "880/880 [==============================] - 0s 472us/step - loss: 0.2829 - accuracy: 0.9170 - val_loss: 0.3641 - val_accuracy: 0.8904\n",
      "Epoch 45/60\n",
      "880/880 [==============================] - 0s 492us/step - loss: 0.2748 - accuracy: 0.9205 - val_loss: 0.4565 - val_accuracy: 0.8699\n",
      "Epoch 46/60\n",
      "880/880 [==============================] - 0s 485us/step - loss: 0.3002 - accuracy: 0.9148 - val_loss: 0.4198 - val_accuracy: 0.8836\n",
      "Epoch 47/60\n",
      "880/880 [==============================] - 0s 473us/step - loss: 0.2935 - accuracy: 0.9182 - val_loss: 0.4214 - val_accuracy: 0.8836\n",
      "Epoch 48/60\n",
      "880/880 [==============================] - 0s 485us/step - loss: 0.2427 - accuracy: 0.9352 - val_loss: 0.3456 - val_accuracy: 0.8904\n",
      "Epoch 49/60\n",
      "880/880 [==============================] - 0s 476us/step - loss: 0.2456 - accuracy: 0.9330 - val_loss: 0.3536 - val_accuracy: 0.9041\n",
      "Epoch 50/60\n",
      "880/880 [==============================] - 0s 485us/step - loss: 0.2396 - accuracy: 0.9420 - val_loss: 0.4138 - val_accuracy: 0.8904\n",
      "Epoch 51/60\n",
      "880/880 [==============================] - 0s 467us/step - loss: 0.2357 - accuracy: 0.9295 - val_loss: 0.4045 - val_accuracy: 0.8973\n",
      "Epoch 52/60\n",
      "880/880 [==============================] - 0s 468us/step - loss: 0.2283 - accuracy: 0.9341 - val_loss: 0.3805 - val_accuracy: 0.9041\n",
      "Epoch 53/60\n",
      "880/880 [==============================] - 0s 495us/step - loss: 0.2461 - accuracy: 0.9330 - val_loss: 0.4130 - val_accuracy: 0.8836\n",
      "Epoch 54/60\n",
      "880/880 [==============================] - 0s 485us/step - loss: 0.2343 - accuracy: 0.9330 - val_loss: 0.4515 - val_accuracy: 0.8973\n",
      "Epoch 55/60\n",
      "880/880 [==============================] - 0s 486us/step - loss: 0.2157 - accuracy: 0.9375 - val_loss: 0.4801 - val_accuracy: 0.8836\n",
      "Epoch 56/60\n",
      "880/880 [==============================] - 0s 518us/step - loss: 0.2031 - accuracy: 0.9398 - val_loss: 0.4630 - val_accuracy: 0.8973\n",
      "Epoch 57/60\n",
      "880/880 [==============================] - 0s 461us/step - loss: 0.1856 - accuracy: 0.9545 - val_loss: 0.4466 - val_accuracy: 0.8973\n",
      "Epoch 58/60\n",
      "880/880 [==============================] - 0s 468us/step - loss: 0.1695 - accuracy: 0.9534 - val_loss: 0.4584 - val_accuracy: 0.9041\n",
      "Epoch 59/60\n",
      "880/880 [==============================] - 0s 478us/step - loss: 0.1840 - accuracy: 0.9523 - val_loss: 0.4115 - val_accuracy: 0.9110\n",
      "Epoch 60/60\n",
      "880/880 [==============================] - 0s 537us/step - loss: 0.1897 - accuracy: 0.9443 - val_loss: 0.4449 - val_accuracy: 0.8973\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f00586d28d0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "num_labels = y_train.shape[1]\n",
    "filter_size = 2\n",
    "\n",
    "# build model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(256, input_shape=(257,)))\n",
    "model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(num_labels))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "# model.summary()\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=10, epochs=60,validation_data=(X_validation,y_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 90.83%\n",
      "activity,Calling,Clapping,Falling,Sweeping,WashingHand,WatchingTV,enteringExiting,other\n",
      "Calling , 7,0,2,0,0,0,2,1\n",
      "Clapping , 0,12,0,0,0,0,0,0\n",
      "Falling , 0,0,9,0,0,0,0,3\n",
      "Sweeping , 0,0,0,6,0,0,0,0\n",
      "WashingHand , 0,0,0,0,4,0,0,2\n",
      "WatchingTV , 0,0,0,0,0,3,0,3\n",
      "enteringExiting , 0,0,0,0,0,0,14,0\n",
      "other , 0,3,2,0,0,2,0,143\n",
      "\n",
      "activity,Calling,Clapping,Falling,Sweeping,WashingHand,WatchingTV,enteringExiting,other\n",
      "Calling , 0.58,0.0,0.17,0.0,0.0,0.0,0.17,0.08\n",
      "Clapping , 0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0\n",
      "Falling , 0.0,0.0,0.75,0.0,0.0,0.0,0.0,0.25\n",
      "Sweeping , 0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0\n",
      "WashingHand , 0.0,0.0,0.0,0.0,0.67,0.0,0.0,0.33\n",
      "WatchingTV , 0.0,0.0,0.0,0.0,0.0,0.5,0.0,0.5\n",
      "enteringExiting , 0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0\n",
      "other , 0.0,0.02,0.01,0.0,0.0,0.01,0.0,0.95\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = model.predict(X_test)\n",
    "\n",
    "cnt = 0\n",
    "for i in range(len(Y_test)):\n",
    "    if(np.amax(result[i])<0.5):\n",
    "#       pred = 11\n",
    "      pred = np.argmax(result[i])\n",
    "    else:\n",
    "      pred = np.argmax(result[i])\n",
    "    if np.argmax(y_test[i])==pred:\n",
    "        cnt+=1\n",
    "\n",
    "acc = str(round(cnt*100/float(len(Y_test)),2))\n",
    "print(\"Accuracy: \" + acc + \"%\")\n",
    "\n",
    "showResult()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## save model (optional)\n",
    "path = \"audio_NN_New\"+datetime.datetime.now().strftime('%Y_%m_%d_%H_%M_%S')\n",
    "model_json = model.to_json()\n",
    "with open(path+\"_acc_\"+acc+\".json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(path+\"_acc_\"+acc+\".h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
